
# https://github.com/elastic/helm-charts/blob/main/logstash/values.yaml
#TODO: Add opensearch output plugin!!

global:
  hostname: &fqdn "devlocal.groundzero.solutions"
  loadBalancerHostname: &do-lb-workaround-hostname "devlocal-lb.groundzero.solutions"

  ospassword: &ospassword "Test@Password01"
  msgbrokerPassword: &msgbrokerPassword P@ssw0rd11!!

  ip-whitelist-internal: &ipwhiteliststring "0.0.0.0/0"
  
  ingressClassName: &ingressClassName "devlocal-dev-nginx"

  certificateIssuerName: &certificateIssuerName "letsencrypt-prod"
  

  # letsencrypt-contact: "rpalethorpe@groundzero.solutions" # TODO: Fix contact paramter [Low]

ingress-nginx:
  install: true

  tcp:
    "5044": "devlocal/qai1-logstash:5044"
    "50000": "devlocal/qai1-logstash:50000"
    "9092": "devlocal/qai-kafka:9092"
    # "9200": "devlocal/qai-elasticsearch:9200"

  controller:
    progressDeadlineSeconds: 600
    # ingressClass: test-nginx
    ingressClassResource:
      name: *ingressClassName
    config:
      allow-snippet-annotations: "true"
      # use-proxy-protocol: "true"
    publishService:
      enabled: true
    service:
    #   annotations:
        # service.beta.kubernetes.io/do-loadbalancer-hostname: *do-lb-workaround-hostname
        # service.beta.kubernetes.io/do-loadbalancer-name: *do-lb-workaround-hostname
        # service.beta.kubernetes.io/do-loadbalancer-size-unit: "1"
        # service.beta.kubernetes.io/do-loadbalancer-type: "REGIONAL_NETWORK"
        # service.beta.kubernetes.io/do-loadbalancer-enable-proxy-protocol: "true"
        # service.beta.kubernetes.io/do-loadbalancer-deny-rules: "cidr:198.51.100.0/16"
      loadBalancerSourceRanges:
        - *ipwhiteliststring
        # - 0.0.0.0/0

logstash:
  install: true

  # image: logstash-opensearch
  image: "registry.digitalocean.com/g0-cr/logstash-opensearch"
  imageTag: latest
  imagePullSecrets:
    - name: g0-cr

  persistence:
    enabled: false

  logstashConfig:
    logstash.yml: |
      api.http.host: "0.0.0.0"
      # xpack.monitoring.elasticsearch.hosts: [ "http://elasticsearch:9200" ]
      # xpack.monitoring.enabled: false

      config.reload.automatic: true
      config.reload.interval: 3s
    pipelines.yml: |
      - pipeline.id: beats-input
        path.config: /usr/share/logstash/ls-pipeline-10-input/*.conf

      - pipeline.id: http-input
        path.config: /usr/share/logstash/ls-pipeline-10-input-http/*.conf

      - pipeline.id: 20-process-split-test-case
        path.config: /usr/share/logstash/ls-pipeline-20-process-split-test-case/*.conf

      - pipeline.id: 20-process-split-test-run
        path.config: /usr/share/logstash/ls-pipeline-20-process-split-test-run/*.conf

      # - pipeline.id: 20-process-split-test-suite
      #   path.config: /usr/share/logstash/ls-pipeline-20-process-split-test-suite/*.conf

      - pipeline.id: final-filter-common
        path.config: /usr/share/logstash/ls-pipeline-30-final-filter-common/*.conf

      - pipeline.id: output-common
        path.config: /usr/share/logstash/ls-pipeline-30-output-common/*.conf

  livenessProbe:
    initialDelaySeconds: 180

  readinessProbe:
    initialDelaySeconds: 20


  envFrom:
    - secretRef:
        name: platform-creds

  extraVolumes:
    - name: certificates-vol
      secret:
        secretName: ca-secret

    - name: ls-pipeline-10-input
      configMap:
        name: ls-pipeline-10-input-cm

    - name: ls-pipeline-10-input-http
      configMap:
        name: ls-pipeline-10-input-http-cm

    - name: ls-pipeline-20-process-split-test-case
      configMap:
        name: ls-pipeline-20-process-split-test-case-cm

    - name: ls-pipeline-20-process-split-test-suite
      configMap:
        name: ls-pipeline-20-process-split-test-suite-cm

    - name: ls-pipeline-20-process-split-test-run
      configMap:
        name: ls-pipeline-20-process-split-test-run-cm

    - name: ls-pipeline-30-final-filter-common
      configMap:
        name: ls-pipeline-30-final-filter-common-cm

    - name: ls-pipeline-30-output-common
      configMap:
        name: ls-pipeline-30-output-common-cm

  extraVolumeMounts:
    - name: certificates-vol
      mountPath: /usr/share/logstash/certs
      readOnly: true

    - name: ls-pipeline-10-input
      mountPath: /usr/share/logstash/ls-pipeline-10-input
      readOnly: true

    - name: ls-pipeline-10-input-http
      mountPath: /usr/share/logstash/ls-pipeline-10-input-http
      readOnly: true

    - name: ls-pipeline-20-process-split-test-case
      mountPath: /usr/share/logstash/ls-pipeline-20-process-split-test-case
      readOnly: true

    - name: ls-pipeline-20-process-split-test-run
      mountPath: /usr/share/logstash/ls-pipeline-20-process-split-test-run
      readOnly: true

    - name: ls-pipeline-20-process-split-test-suite
      mountPath: /usr/share/logstash/ls-pipeline-20-process-split-test-suite
      readOnly: true

    - name: ls-pipeline-30-final-filter-common
      mountPath: /usr/share/logstash/ls-pipeline-30-final-filter-common
      readOnly: true

    - name: ls-pipeline-30-output-common
      mountPath: /usr/share/logstash/ls-pipeline-30-output-common
      readOnly: true

  extraPorts:
    - name: test-results
      containerPort: 5044
    - name: results-http
      containerPort: 50000

  service:
    type: ClusterIP
    ports:
      - name: test-results
        port: 5044
        protocol: TCP
        targetPort: 5044
      - name: results-http
        port: 50000
        protocol: TCP
        targetPort: 50000


  # resources:
  #   requests:
  #     cpu: "100m"
  #     memory: "300Mi"
  #   limits:
  #     cpu: "500m"
  #     memory: "900Mi"


  ingress:
    enabled: false
    annotations:
      kubernetes.io/ingress.class: *ingressClassName
      nginx.ingress.kubernetes.io/whitelist-source-range: *ipwhiteliststring
    className: *ingressClassName
    pathtype: ImplementationSpecific
    hosts:
      - host: *fqdn
        paths:
          - path: /beats
            servicePort: 5044
          - path: /http
            servicePort: 50000

    tls:
     - secretName: tls-certificate

opensearch:
  install: true
  singleNode: true

  image:
    tag: "3.0.0"

  resources:
    requests:
      cpu: "250m"
      memory: "500Mi"

  startupProbe:
    initialDelaySeconds: 30

  sysctlInit:
    enabled: true

  extraEnvs:
  - name: OPENSEARCH_INITIAL_ADMIN_PASSWORD
    valueFrom:
      secretKeyRef:
        key:  OS_PASSWORD
        name: platform-creds
  #   - name: DISABLE_SECURITY_PLUGIN
  #     value: "false"

  # secretMounts:
  # - name: tls-certificate
  #   mountPath: /usr/share/opensearch/config
  #   path: /usr/share/opensearch/config/esnode.pem
  #   subPath: tls.crt
  # - name: tls-certificate
  #   mountPath: /usr/share/opensearch/config
  #   path: /usr/share/opensearch/config/esnode-key.pem
  #   subPath: tls.key

  config:
    # log4j2.properties: |
    #   status = error
    #
    #   appender.console.type = Console
    #   appender.console.name = console
    #   appender.console.layout.type = PatternLayout
    #   appender.console.layout.pattern = [%d{ISO8601}][%-5p][%-25c{1.}] [%node_name]%marker %m%n
    #
    #   rootLogger.level = info
    #   rootLogger.appenderRef.console.ref = console
    opensearch.yml: |
      cluster.name: opensearch-cluster

      # Bind to all interfaces because we don't know what IP address Docker will assign to us.
      network.host: 0.0.0.0

      # discovery.type: single-node

      # # TODO: Remove for prod\cust installs
      # reindex.remote.whitelist: ["*.svc.cluster.local:9200", "*:920*"]
      
      reindex.ssl.verification_mode: none

      # For security plugin - session timeouts - DISABLED - these do not work
      # opensearch_security.cookie.ttl: 86400000
      # opensearch_security.session.ttl: 86400000
      # opensearch_security.session.keepalive: true

      script.painless.regex.enabled: true
      
      path.repo: ["/usr/share/opensearch/data/snapshots"]
      

  lifecycle:
    postStart:
      exec:
        command:
          - /bin/sh
          - -c
          - |
            echo "Waiting for OpenSearch to be ready..."
            until curl -s -u "admin:${OPENSEARCH_INITIAL_ADMIN_PASSWORD}" https://localhost:9200 --insecure; do
              sleep 5
            done
            echo "OpenSearch is up. Running post-start command..."
            cd /usr/share/opensearch/install-files/
            curl -XPUT https://localhost:9200/_template/tosca-template -u "admin:${OPENSEARCH_INITIAL_ADMIN_PASSWORD}" -H 'Content-Type: application/json' --insecure --data @./tosca-template.json
            curl -XPUT https://localhost:9200/_template/tosca-healthcheck -u "admin:${OPENSEARCH_INITIAL_ADMIN_PASSWORD}" -H 'Content-Type: application/json' --insecure --data @./tosca-healthchecks.json
            curl -XPUT https://localhost:9200/_template/tosca-systeminfo -u "admin:${OPENSEARCH_INITIAL_ADMIN_PASSWORD}" -H 'Content-Type: application/json' --insecure --data @./tosca-systeminfo.json

            curl -XPUT https://localhost:9200//_snapshot/repo-backups -u "admin:${OPENSEARCH_INITIAL_ADMIN_PASSWORD}" -H 'Content-Type: application/json' --insecure --data '
            {
              "type": "fs",
              "settings": {
                "location": "/usr/share/opensearch/data/snapshots"
              }
            }'


  extraVolumes:
    - name: install-files
      configMap:
        name: opensearch-install-files-cm

  extraVolumeMounts:
    - name: install-files
      mountPath: /usr/share/opensearch/install-files/
      readOnly: false

  persistence:
    enabled: true
    enableInitChown: true
    labels:
      enabled: true
      additionalLabels:
        app: opensearch
    storageClass: "hostpath"
    accessModes:
      - ReadWriteOnce
    size: 1Gi

opensearch-dashboards:
  install: true
  # opensearchHosts: "https://opensearch-cluster-master:9200"
  replicaCount: 1

  image:
    tag: "3.0.0"


  # extraEnvs:
  # - name: "DISABLE_SECURITY_PLUGIN"
  #   value: "false"

  config:
     opensearch_dashboards.yml:
      server:
        name: dashboards
        host: "{{ .Values.serverHost }}"

      opensearch.ssl.verificationMode: none

      opensearch.username: "admin"
      opensearch.password: "{{ .Values.global.ospassword }}"

      assistant.chat.enabled: true

      # Dashboards TLS Config (Ensure the cert files are present before enabling SSL
      # ssl:
      #   enabled: true
      #   key: /usr/share/opensearch-dashboards/certs/dashboards-key.pem
      #   certificate: /usr/share/opensearch-dashboards/certs/dashboards-crt.pem

      # determines how dashboards will verify certificates (needs to be none for default opensearch certificates to work)
      # opensearch:
      #     certificateAuthorities: /usr/share/opensearch-dashboards/certs/dashboards-root-ca.pem
      #     if utilizing custom CA certs for connection to opensearch, provide the CA here


      # https://github.com/opensearch-project/OpenSearch-Dashboards/blob/main/config/opensearch_dashboards.yml

      # application_config.enabled: true
      # opensearchDashboards.defaultAppId: "discover" # DEPRECATED
      home.disableWelcomeScreen: true

      # Optional setting that controls the permissions of data source to create, update and delete.
      # "none": The data source is readonly for all users.
      # "dashboard_admin": The data source can only be managed by dashboard admin.
      # "all": The data source can be managed by all users. Default to "all".
      # data_source_management.manageableBy: "dashboard_admin"

      # Set the value of this setting to false to hide the help menu link to the OpenSearch Dashboards user survey
      # opensearchDashboards.survey.url: "false"

      # @experimental Set the value of this setting to display navigation updates, including dev tool top right navigation
      # opensearchDashboards.futureNavigation: false

      opensearch_security.multitenancy.enabled: true

      workspace.enabled: false
      # uiSettings:
      #   overrides:
      #     "home:useNewHomePage": true

      # Set the value to true to enable Ui Metric Collectors in Usage Collector
      # This publishes the Application Usage and UI Metrics into the saved object, which can be accessed by /api/stats?extended=true&legacy=true&exclude_usage=false
      usageCollection.uiMetric.enabled: false

      # Set the value to true to enable dynamic config service to obtain configs from a config store. By default, it's disabled
      # dynamic_config_service.enabled: false

      # Set the value to true to enable direct data import from a file
      # data_importer.enabled: true
      # Not working on 2.19.x - what version

      # assistant.chat.enabled: true

      opensearchDashboards.branding:
        logo:
          defaultUrl: "https://dev.w3.org/SVG/tools/svgweb/samples/svg-files/atom.svg"
          darkModeUrl: "https://dev.w3.org/SVG/tools/svgweb/samples/svg-files/atom.svg"
        mark:
          defaultUrl: "https://dev.w3.org/SVG/tools/svgweb/samples/svg-files/atom.svg"
          darkModeUrl: "https://dev.w3.org/SVG/tools/svgweb/samples/svg-files/atom.svg"
        loadingLogo:
          defaultUrl: "https://dev.w3.org/SVG/tools/svgweb/samples/svg-files/atom.svg"
          darkModeUrl: "https://dev.w3.org/SVG/tools/svgweb/samples/svg-files/atom.svg"
        faviconUrl: ""
        applicationTitle: "AnalytiQa [Qualtiva]"

      # securityAnalyticsDashboards.enabled: false
      # traceAnalyticsDashboards.enabled: false
      # oberservabilityDashboards.enabled: false
      # notebooksDashboards.enabled: false
    
  ingress:
    enabled: true
    ingressClassName: *ingressClassName
    annotations:
      kubernetes.io/ingress.class: *ingressClassName
      cert-manager.io/cluster-issuer: *certificateIssuerName
      # nginx.ingress.kubernetes.io/whitelist-source-range: *ipwhiteliststring
      # nginx.ingress.kubernetes.io/use-regex: 'true'
      # nginx.ingress.kubernetes.io/rewrite-target: /$2
      # cert-manager.io/cluster-issuer: "selfsigned-issuer"
      # cert-manager.io/issuer: "selfsigned-cluster-issuer"
    hosts:
      - host: *fqdn
        paths:
          - path: /
            # pathType: ImplementationSpecific
            backend:
              serviceName: ""
              servicePort: ""
    tls:
    - hosts:
        - *fqdn
      secretName: tls-certificate
      

rabbitmq:
  install: false
  image:
    repository: bitnami/rabbitmq
  auth:
    username: admin
    password: *ospassword
    updatePassword: true
    # securePassword: true
    tls:
      enabled: false
      skipVerify: true
      verify: verify_none
      existingSecret: tls-certificate
      # existingSecretFullChain: true
      failIfNoPeerCert: false

  extraPlugins: >
    rabbitmq_auth_backend_ldap
    rabbitmq_consistent_hash_exchange
    rabbitmq_shovel
    rabbitmq_shovel_management
    rabbitmq_federation
    rabbitmq_federation_management

  serviceAccount:
    create: true

  service:
    managerPortEnabled: true

  resources:
    limits:
      cpu: 500m
      memory: 1Gi
    requests:
      cpu: 150m
      memory: 250Mi

  # # Note: Not tested, should be fine though
  # persistance:
  #   enabled: false
  #   size: 1Gi
  #   storageClass: "do-block-storage-retain"
  #   accessModes:
  #     - ReadWriteOnce

  ingress:
    enabled: true
    ingressClassName: *ingressClassName
    hostname: *fqdn
    existingSecret: tls-certificate
    tls: true
    path: /ampq
    # extraPaths:
    # - path: /mqadmin
    #   pathType: Prefix
    #   backend:
    #     service:
    #       name: qarp-2-rabbitmq
    #       port:
    #         name: http-stats
    annotations:
      kubernetes.io/ingress.class: *ingressClassName
      # cert-manager.io/cluster-issuer: "letsencrypt-staging"
      nginx.ingress.kubernetes.io/whitelist-source-range: *ipwhiteliststring

kafka:
  install: false
  
  clusterId: "kafka-cluster"
  replicaCount: 1
  
  # image:
  #   tag: 3.9.0
  # sasl:
  #   existingSecret: message-broker-secret

  # sasl.client.users[0]: user1
  # sasl.client.passwords[0]: *msgbrokerPassword

  # # sasl.interbroker.user[0]: inter_broker_user
  # sasl.interbroker.password: *msgbrokerPassword

  # # sasl.controller.user[0]: inter_broker_user
  # sasl.controller.password: *msgbrokerPassword

  tls:
    type: PEM
    existingSecret: tls-certificate

  controller:
    replicaCount: 1

  provisioning:
    enabled: true
    topics:
      - name: "qa-logs"
        partitions: 1
        replicationFactor: 1
        config:
          retention.ms: 604800000 # 7 days
          segment.bytes: 1073741824 # 1GB

  resources:
    limits:
      cpu: 300m
      memory: 5Gi
    requests:
      cpu: 100m
      memory: 200Mi
  
  # TODO: If re-enable - persistance and sizing
strimzi-kafka-operator:
  install: false
  replicas: 1

kafka-ui:
  install: false

  env:
    - name: DYNAMIC_CONFIG_ENABLED
      value: "true"

  yamlApplicationConfig:
    # kafka:
    #   clusters:
    #     - name: qai1-kafka
    #       bootstrapServers:  qai1-kafka:9092
    auth:
      type: disabled



